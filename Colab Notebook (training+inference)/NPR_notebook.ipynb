{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j5YYlJ3QELH"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qPyP9DkqOIhr"
      },
      "outputs": [],
      "source": [
        "# --- Core YOLO + OCR libraries ---\n",
        "!pip install ultralytics==8.3.203  # stable YOLOv8\n",
        "!pip install easyocr               # OCR model\n",
        "!pip install pytesseract           # wrapper for Tesseract OCR\n",
        "!pip install opencv-python         # OpenCV\n",
        "!apt-get install -y tesseract-ocr libtesseract-dev  # system Tesseract engine\n",
        "\n",
        "# --- Extra utils ---\n",
        "!pip install filterpy              # Kalman filter (tracking)\n",
        "!pip install roboflow              # for Roboflow dataset download\n",
        "\n",
        "# --- Fix sympy bug with torch.compile ---\n",
        "!pip install sympy==1.12\n",
        "\n",
        "# 2. Download sort.py\n",
        "!wget https://raw.githubusercontent.com/abewley/sort/master/sort.py -O sort.py\n",
        "\n",
        "# 3. Remove plotting lines (matplotlib/skimage not needed)\n",
        "!sed -i '/import matplotlib/d' sort.py\n",
        "!sed -i '/matplotlib.use/d' sort.py\n",
        "!sed -i '/from skimage/d' sort.py\n",
        "!sed -i '/import pylab/d' sort.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hK4LxoJ2PgP"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"MYgV2qq7j4x6PO0L7jdm\")   ## get API key\n",
        "project = rf.workspace(\"roboflow-universe-projects\").project(\"license-plate-recognition-rxg4e\")\n",
        "dataset = project.version(11).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwPRzvGP3k38"
      },
      "outputs": [],
      "source": [
        "!du -sh /content/License-Plate-Recognition-11/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmZzmUMA38Gx"
      },
      "outputs": [],
      "source": [
        "!find /content/License-Plate-Recognition-11/train/images -type f | wc -l    # Training Images  ---- 7057\n",
        "!find /content/License-Plate-Recognition-11/valid/images -type f | wc -l    # Validation Images --- 2048\n",
        "!find /content/License-Plate-Recognition-11/test/images -type f | wc -l     # Test Images       --- 1020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kucRoLVyQdtb"
      },
      "source": [
        "# Train Model---70% Train-20% Val-- 10% Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xdicfotgKtin"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pretrained YOLOv8 small\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    data=\"License-Plate-Recognition-11/data.yaml\",\n",
        "    epochs=80,\n",
        "    imgsz=960,\n",
        "    batch=16,\n",
        "    freeze=4,\n",
        "    patience=15,# fits on Colab T4/A100\n",
        "    workers=2,\n",
        "    cache=False,\n",
        "    amp=True,\n",
        "    project=\"/content/Yolo_project\",\n",
        "    name=\"lp_exp1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkDogHv_QsZ3"
      },
      "source": [
        "## Loading Best Trained Model and Predict on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g7RADv0lQuVB"
      },
      "outputs": [],
      "source": [
        "# Load best model\n",
        "model = YOLO('best.pt')\n",
        "\n",
        "# Run inference on test images\n",
        "results = model.predict('/content/datasets/test/images', save=True,\n",
        "                        save_txt=True,\n",
        "                        save_conf=True,\n",
        "                        project='/content/YOLO_project',\n",
        "                        name='predict')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hILr58iwQ-oA"
      },
      "source": [
        "## Utility Functions for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oisTWbhWxrL"
      },
      "outputs": [],
      "source": [
        "import glob, os, cv2\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    inter_area = max(0, x2-x1) * max(0, y2-y1)\n",
        "    box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
        "    box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
        "    return inter_area / (box1_area + box2_area - inter_area + 1e-6)\n",
        "\n",
        "\n",
        "def yolo_to_xyxy(xc, yc, w, h, img_w, img_h):\n",
        "    x1 = (xc - w/2) * img_w\n",
        "    y1 = (yc - h/2) * img_h\n",
        "    x2 = (xc + w/2) * img_w\n",
        "    y2 = (yc + h/2) * img_h\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "true_dir = \"/content/datasets/test/labels\"  # GT labels\n",
        "pred_dir = \"/content//YOLO_project/predict/labels\"  # YOLO predictions\n",
        "img_dir  = \"/content/datasets/test/images\"\n",
        "\n",
        "iou_threshold = 0.5\n",
        "summary = []\n",
        "\n",
        "for true_file in glob.glob(os.path.join(true_dir, \"*.txt\")):\n",
        "    image_id = os.path.basename(true_file).replace(\".txt\", \"\")\n",
        "    pred_file = os.path.join(pred_dir, image_id + \".txt\")\n",
        "    img_path  = os.path.join(img_dir, image_id + \".jpg\")\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        continue\n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    # -------- Ground truth --------\n",
        "    true_boxes = []\n",
        "    with open(true_file, \"r\") as f:\n",
        "        for line in f.readlines():\n",
        "            vals = line.strip().split()\n",
        "            if len(vals) == 5:  # cls xc yc w h\n",
        "                cls, xc, yc, w, h = map(float, vals)\n",
        "                x1, y1, x2, y2 = yolo_to_xyxy(xc, yc, w, h, img_w, img_h)\n",
        "                true_boxes.append([int(cls), x1, y1, x2, y2])\n",
        "\n",
        "    # -------- Predictions --------\n",
        "    pred_boxes = []\n",
        "    if os.path.exists(pred_file):\n",
        "        with open(pred_file, \"r\") as f:\n",
        "            for line in f.readlines():\n",
        "                vals = line.strip().split()\n",
        "                if len(vals) == 6:  # cls xc yc w h conf\n",
        "                    cls, xc, yc, w, h, conf = map(float, vals)\n",
        "                    x1, y1, x2, y2 = yolo_to_xyxy(xc, yc, w, h, img_w, img_h)\n",
        "                    pred_boxes.append([int(cls), x1, y1, x2, y2, conf])\n",
        "\n",
        "    # -------- IoU Matching --------\n",
        "    matched, missed, false_pos = 0, 0, 0\n",
        "    used_preds = set()\n",
        "\n",
        "    for tb in true_boxes:\n",
        "        found_match = False\n",
        "        for i, pb in enumerate(pred_boxes):\n",
        "            iou = compute_iou(tb[1:], pb[1:5])\n",
        "            if iou >= iou_threshold and i not in used_preds:\n",
        "                matched += 1\n",
        "                used_preds.add(i)\n",
        "                found_match = True\n",
        "                break\n",
        "        if not found_match:\n",
        "            missed += 1\n",
        "\n",
        "    false_pos = len(pred_boxes) - len(used_preds)\n",
        "    summary.append([image_id, matched, missed, false_pos])\n",
        "\n",
        "# Totals\n",
        "total_TP = sum(r[1] for r in summary)\n",
        "total_FN = sum(r[2] for r in summary)\n",
        "total_FP = sum(r[3] for r in summary)\n",
        "\n",
        "overall_precision = total_TP / (total_TP + total_FP + 1e-6)\n",
        "overall_recall    = total_TP / (total_TP + total_FN + 1e-6)\n",
        "overall_accuracy  = total_TP / (total_TP + total_FP + total_FN + 1e-6)\n",
        "\n",
        "print(\"\\n📊 Final Totals Across Test Set:\")\n",
        "print(f\"TP={total_TP}, FN={total_FN}, FP={total_FP}\")\n",
        "print(f\"Precision={overall_precision:.3f}, Recall={overall_recall:.3f}, Accuracy={overall_accuracy:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FzazF-tV4tG"
      },
      "source": [
        "## Main Pipeline For Plate Detection From Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0n2i5YVY6YC"
      },
      "source": [
        "\n",
        "\n",
        "### Indian Number Plate Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqOOLVmnoDar"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sqlite3\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from sort import Sort\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow  # for Colab debugging\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Utility functions\n",
        "# ---------------------------\n",
        "def compute_iou(boxA, boxB):\n",
        "    \"\"\"Compute IoU between two boxes [x1,y1,x2,y2].\"\"\"\n",
        "    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])\n",
        "    xB, yB = min(boxA[2], boxB[2]), min(boxA[3], boxB[3])\n",
        "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
        "    areaA = max(0, (boxA[2] - boxA[0])) * max(0, (boxA[3] - boxA[1]))\n",
        "    areaB = max(0, (boxB[2] - boxB[0])) * max(0, (boxB[3] - boxB[1]))\n",
        "    return inter_area / (areaA + areaB - inter_area + 1e-6)\n",
        "\n",
        "\n",
        "def preprocess_plate(plate_crop):\n",
        "    \"\"\"Preprocess license plate image for OCR clarity.\"\"\"\n",
        "    if plate_crop is None or plate_crop.size == 0:\n",
        "        return None\n",
        "\n",
        "    # 1. Upscale moderately\n",
        "    plate_crop = cv2.resize(plate_crop, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # 2. Grayscale\n",
        "    gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 3. Gentle denoising\n",
        "    gray = cv2.bilateralFilter(gray, d=5, sigmaColor=40, sigmaSpace=40)\n",
        "\n",
        "    # 4. Contrast enhancement (CLAHE preserves edges)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    gray = clahe.apply(gray)\n",
        "\n",
        "    # 5. Thresholding (binary inverse for Tesseract)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # 6. Morphological OPEN (remove small dots)\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "\n",
        "    # 7. Invert (black text on white background for OCR)\n",
        "    return cv2.bitwise_not(thresh)\n",
        "\n",
        "\n",
        "##Indian NumBer Plate Recognition\n",
        "def read_plate_text(img, easy_reader=None, conf_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Read license-plate text from a *preprocessed* plate image.\n",
        "    Returns (plate_text, confidence in [0..1]).\n",
        "    Strategy:\n",
        "      1) Try Tesseract with several PSMs.\n",
        "      2) Optionally try EasyOCR.\n",
        "      3) Clean + correct lookalikes by slot (letters vs digits).\n",
        "      4) Score candidates with Indian-plate regex; pick the best.\n",
        "    \"\"\"\n",
        "\n",
        "    if img is None or img.size == 0:\n",
        "        return \"UNKNOWN\", 0.0\n",
        "\n",
        "    # -------- helpers --------\n",
        "    def run_tess(psm):\n",
        "        cfg = f\"--psm {psm} --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
        "        d = pytesseract.image_to_data(img, config=cfg, output_type=pytesseract.Output.DICT)\n",
        "        raw = \"\".join([t for t in d[\"text\"] if t.strip()]).upper()\n",
        "        confs = [float(c) for c in d[\"conf\"] if str(c) != \"-1\"]\n",
        "        avg = (np.mean(confs) / 100.0) if confs else 0.0\n",
        "        return raw, avg\n",
        "\n",
        "    def clean(s):  # remove junk and clamp length\n",
        "        s = re.sub(r\"[^A-Z0-9]\", \"\", s.upper())\n",
        "        return s[:12]\n",
        "\n",
        "    # Map digits<->letters only where they don't belong\n",
        "    letter_map = {'0':'O','1':'I','2':'Z','5':'S','8':'B','6':'G','4':'A'}\n",
        "    digit_map  = {'O':'0','D':'0','Q':'0','I':'1','L':'1','Z':'2','S':'5','B':'8','G':'6','T':'7'}\n",
        "\n",
        "    def fix_by_slots(s):\n",
        "        s = list(clean(s))\n",
        "        n = len(s)\n",
        "        if n == 0:\n",
        "            return \"\"\n",
        "\n",
        "        # Expected Indian-style: LL DD L[L] DDDD (length 8–10)\n",
        "        # force letters at 0-1\n",
        "        for i in range(min(2, n)):\n",
        "            if s[i].isdigit():\n",
        "                s[i] = letter_map.get(s[i], s[i])\n",
        "        # digits at 2-3\n",
        "        for i in range(2, min(4, n)):\n",
        "            if s[i].isalpha():\n",
        "                s[i] = digit_map.get(s[i], s[i])\n",
        "        # one or two letters at 4-5\n",
        "        for i in range(4, min(6, n)):\n",
        "            if s[i].isdigit():\n",
        "                s[i] = letter_map.get(s[i], s[i])\n",
        "        # last 4 must be digits\n",
        "        for i in range(max(6, n-4), n):\n",
        "            if i >= 0 and i < n and s[i].isalpha():\n",
        "                s[i] = digit_map.get(s[i], s[i])\n",
        "\n",
        "        # if still too long, prefer keeping last 4 digits\n",
        "        s = \"\".join(s)\n",
        "        if len(s) > 10:\n",
        "            s = s[:10]\n",
        "        return s\n",
        "\n",
        "    patterns = [\n",
        "        re.compile(r'^[A-Z]{2}\\d{2}[A-Z]{2}\\d{4}$'),   # KA02MN1826\n",
        "        re.compile(r'^[A-Z]{2}\\d{2}[A-Z]{1}\\d{4}$'),   # KA02M1826\n",
        "        re.compile(r'^[A-Z]{2}\\d{1}[A-Z]{2}\\d{4}$')    # older variants\n",
        "    ]\n",
        "    def score(s, base_conf):\n",
        "        s = clean(s)\n",
        "        sc = base_conf + 0.05 * min(len(s), 10)\n",
        "        if any(p.fullmatch(s) for p in patterns):\n",
        "            sc += 0.5     # strong format bonus\n",
        "        return s, sc\n",
        "\n",
        "    # -------- collect candidates --------\n",
        "    cands = []\n",
        "    for psm in (8, 7, 13):                      # 8=word, 7=single line, 13=raw line\n",
        "        raw, conf = run_tess(psm)\n",
        "        cands.append((raw, conf))\n",
        "\n",
        "    if easy_reader is not None:\n",
        "        try:\n",
        "            r = easy_reader.readtext(img, detail=1, paragraph=False)\n",
        "            if r:\n",
        "                cands.append( (r[0][1].upper(), float(r[0][2])) )\n",
        "        except Exception as e:\n",
        "            print(f\"[EasyOCR error] {e}\")\n",
        "\n",
        "    # -------- normalize, correct, choose best --------\n",
        "    best_text, best_score = \"UNKNOWN\", 0.0\n",
        "    for raw, conf in cands:\n",
        "        fixed = fix_by_slots(raw)               # O→0, Z→2 etc by position\n",
        "        s, sc = score(fixed, conf)\n",
        "        if 7 <= len(s) <= 10 and sc > best_score:\n",
        "            best_text, best_score = s, sc\n",
        "\n",
        "    # As a last resort, try image_to_string (sometimes returns a cleaner line)\n",
        "    if best_score < 0.25:\n",
        "        fallback = pytesseract.image_to_string(\n",
        "            img,\n",
        "            config=\"--psm 7 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
        "        ).upper()\n",
        "        fixed = fix_by_slots(fallback)\n",
        "        s, sc = score(fixed, 0.25)\n",
        "        if sc > best_score:\n",
        "            best_text, best_score = s, sc\n",
        "\n",
        "    return best_text, float(max(0.0, min(1.0, best_score)))\n",
        "\n",
        "\n",
        "\n",
        "def save_crop(crop, frame_id, output_dir):\n",
        "    \"\"\"Save cropped plate images for debugging.\"\"\"\n",
        "    crops_dir = os.path.join(output_dir, \"crops_4\")\n",
        "    os.makedirs(crops_dir, exist_ok=True)\n",
        "    path = os.path.join(crops_dir, f\"frame{frame_id}_plate.jpg\")\n",
        "    cv2.imwrite(path, crop)\n",
        "    return path\n",
        "\n",
        "\n",
        "def insert_db(cursor, frame_id, track_id, vlabel, vx1, vy1, vx2, vy2,\n",
        "              x1, y1, x2, y2, plate_text, ocr_confidence):\n",
        "    \"\"\"Insert detection into SQLite DB with vehicle type and OCR confidence.\"\"\"\n",
        "    cursor.execute(\n",
        "        \"INSERT INTO plates (plate_text, ocr_confidence, frame_id, vehicle_id, vehicle_type, vehicle_bbox, plate_bbox) VALUES (?, ?, ?, ?, ?, ?, ?)\",\n",
        "        (plate_text, ocr_confidence, frame_id, track_id, vlabel,\n",
        "         f\"{vx1},{vy1},{vx2},{vy2}\", f\"{x1},{y1},{x2},{y2}\")\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Main ANPR pipeline\n",
        "# ---------------------------\n",
        "def run_npr(video_path, output_dir, conf=0.25):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # --- Setup DB ---\n",
        "    db_path = os.path.join(output_dir, \"plates_4.db\")\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    c = conn.cursor()\n",
        "    c.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS plates\n",
        "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "     plate_text TEXT,\n",
        "     ocr_confidence REAL,\n",
        "     timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "     frame_id INTEGER,\n",
        "     vehicle_id INTEGER,\n",
        "     vehicle_type TEXT,\n",
        "     vehicle_bbox TEXT,\n",
        "     plate_bbox TEXT)\n",
        "    ''')\n",
        "    conn.commit()\n",
        "\n",
        "    # --- Load models ---\n",
        "    vehicle_model = YOLO(\"yolov8s.pt\")   # vehicles\n",
        "    plate_model   = YOLO(\"/content/drive/MyDrive/YOLO_project/output/best.pt\")  # license plates\n",
        "\n",
        "    # --- Video setup ---\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
        "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    print(f\"Video resolution: {width}x{height}, FPS={fps}\")\n",
        "\n",
        "    out_path = os.path.join(output_dir, \"annotated_video_4.mp4\")\n",
        "    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
        "\n",
        "    tracker = Sort(max_age=5, min_hits=3, iou_threshold=0.1)\n",
        "    frame_count, db_inserts = 0, 0\n",
        "\n",
        "    # --- Processing loop ---\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_count += 1\n",
        "\n",
        "        # --- Detect vehicles ---\n",
        "        results_vehicle = vehicle_model(frame, imgsz=960, conf=conf)[0]\n",
        "        detections, vehicle_data = [], []\n",
        "        for box in results_vehicle.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            vlabel = vehicle_model.names[cls_id]\n",
        "            if vlabel in [\"car\", \"bus\", \"motorcycle\", \"truck\"]:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                score = float(box.conf[0])\n",
        "                detections.append([x1, y1, x2, y2, score])\n",
        "                vehicle_data.append((x1, y1, x2, y2, vlabel))\n",
        "        tracked_objects = tracker.update(np.array(detections) if len(detections) > 0 else np.empty((0, 5)))\n",
        "\n",
        "        # --- Detect plates ---\n",
        "        results_plate = plate_model(frame, imgsz=960, conf=conf)[0]\n",
        "        print(f\"[Frame {frame_count}] Vehicles={len(vehicle_data)}, Plates={len(results_plate.boxes)}\")\n",
        "\n",
        "        for box in results_plate.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "\n",
        "            # --- Match plate with vehicles ---\n",
        "            matched_vehicle, best_iou, matched_track_id, matched_vlabel = None, 0, -1, \"UNKNOWN\"\n",
        "            for (vx1, vy1, vx2, vy2, vlabel) in vehicle_data:\n",
        "                for (tx1, ty1, tx2, ty2, track_id) in tracked_objects:\n",
        "                    iou = compute_iou([x1,y1,x2,y2], [tx1,ty1,tx2,ty2])\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        matched_vehicle = (vx1, vy1, vx2, vy2)\n",
        "                        matched_track_id = int(track_id)\n",
        "                        matched_vlabel = vlabel\n",
        "\n",
        "            # --- OCR ---\n",
        "            plate_crop = frame[y1:y2, x1:x2]\n",
        "            save_crop(plate_crop, frame_count, output_dir)  # save debug crop\n",
        "            preprocessed = preprocess_plate(plate_crop)\n",
        "            plate_text, ocr_conf = read_plate_text(preprocessed)\n",
        "\n",
        "            # --- Save to DB (only if valid plate found) ---\n",
        "            if plate_text != \"UNKNOWN\" and ocr_conf > 0.3:\n",
        "                vx1, vy1, vx2, vy2 = matched_vehicle if matched_vehicle else (-1, -1, -1, -1)\n",
        "                insert_db(c, frame_count, matched_track_id, matched_vlabel,\n",
        "                          vx1, vy1, vx2, vy2, x1, y1, x2, y2,\n",
        "                          plate_text, ocr_conf)\n",
        "                conn.commit()\n",
        "                db_inserts += 1\n",
        "\n",
        "            # --- Draw annotations ---\n",
        "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "            cv2.putText(frame, f\"{plate_text} ({ocr_conf:.2f})\", (x1, y1-5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "            if matched_vehicle:\n",
        "                vx1, vy1, vx2, vy2 = matched_vehicle\n",
        "                cv2.rectangle(frame, (vx1,vy1), (vx2,vy2), (255,0,0), 2)\n",
        "                cv2.putText(frame, f\"{matched_vlabel} ID {matched_track_id}\", (vx1, vy1-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)\n",
        "\n",
        "        # Show every 30th frame in Colab\n",
        "        if frame_count % 30 == 0:\n",
        "            cv2_imshow(frame)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    conn.close()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(f\"✅ Video saved: {out_path}\")\n",
        "    print(f\"✅ Database saved: {db_path} with {db_inserts} valid rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqBaz47_Y--l"
      },
      "source": [
        "### UK Number Plate Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHyQON3LSY38"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sqlite3\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from sort import Sort\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow  # for Colab debugging\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Utility functions\n",
        "# ---------------------------\n",
        "def compute_iou(boxA, boxB):\n",
        "    \"\"\"Compute IoU between two boxes [x1,y1,x2,y2].\"\"\"\n",
        "    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])\n",
        "    xB, yB = min(boxA[2], boxB[2]), min(boxA[3], boxB[3])\n",
        "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
        "    areaA = max(0, (boxA[2] - boxA[0])) * max(0, (boxA[3] - boxA[1]))\n",
        "    areaB = max(0, (boxB[2] - boxB[0])) * max(0, (boxB[3] - boxB[1]))\n",
        "    return inter_area / (areaA + areaB - inter_area + 1e-6)\n",
        "\n",
        "\n",
        "def preprocess_plate(plate_crop):\n",
        "    \"\"\"Preprocess license plate image for OCR clarity.\"\"\"\n",
        "    if plate_crop is None or plate_crop.size == 0:\n",
        "        return None\n",
        "    plate_crop = cv2.resize(plate_crop, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
        "    gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.bilateralFilter(gray, d=5, sigmaColor=40, sigmaSpace=40)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    gray = clahe.apply(gray)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "    return cv2.bitwise_not(thresh)\n",
        "\n",
        "\n",
        "def correct_uk_plate(raw_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Correct OCR errors for UK number plates (AA NN AAA).\n",
        "    \"\"\"\n",
        "    plate = re.sub(r\"[^A-Z0-9]\", \"\", raw_text.upper())\n",
        "    if len(plate) != 7:\n",
        "        return plate  # skip correction if length not 7\n",
        "\n",
        "    corrections = list(plate)\n",
        "\n",
        "    # First 2 → letters\n",
        "    for i in [0, 1]:\n",
        "        if corrections[i].isdigit():\n",
        "            corrections[i] = {\"0\": \"O\", \"1\": \"I\", \"5\": \"S\"}.get(corrections[i], corrections[i])\n",
        "\n",
        "    # Middle 2 → digits\n",
        "    for i in [2, 3]:\n",
        "        if corrections[i].isalpha():\n",
        "            corrections[i] = {\"O\": \"0\", \"I\": \"1\", \"S\": \"5\", \"B\": \"8\", \"G\": \"6\"}.get(corrections[i], corrections[i])\n",
        "\n",
        "    # Last 3 → letters\n",
        "    for i in [4, 5, 6]:\n",
        "        if corrections[i].isdigit():\n",
        "            corrections[i] = {\"0\": \"O\", \"1\": \"I\", \"5\": \"S\", \"6\": \"G\", \"8\": \"B\"}.get(corrections[i], corrections[i])\n",
        "\n",
        "    return \"\".join(corrections)\n",
        "\n",
        "\n",
        "def read_plate_text(img):\n",
        "    \"\"\"Reads UK format license plate text using Tesseract OCR. Returns (text, confidence).\"\"\"\n",
        "    plate_text, confidence = \"UNKNOWN\", 0.0\n",
        "    if img is not None:\n",
        "        config = \"--psm 7 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
        "        try:\n",
        "            data = pytesseract.image_to_data(img, config=config, output_type=pytesseract.Output.DICT)\n",
        "            texts = [t.strip().upper() for t in data[\"text\"] if t.strip()]\n",
        "            confs = [int(c) for c in data[\"conf\"] if str(c) != '-1']\n",
        "\n",
        "            if texts:\n",
        "                raw_text = \"\".join(texts)\n",
        "                plate_text = correct_uk_plate(raw_text)\n",
        "                confidence = max(confs) / 100 if confs else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"[Tesseract error] {e}\")\n",
        "    return plate_text, confidence\n",
        "\n",
        "\n",
        "def save_crop(crop, frame_id, output_dir):\n",
        "    \"\"\"Save cropped plate images for debugging.\"\"\"\n",
        "    crops_dir = os.path.join(output_dir, \"crops_final\")\n",
        "    os.makedirs(crops_dir, exist_ok=True)\n",
        "    path = os.path.join(crops_dir, f\"frame{frame_id}_plate.jpg\")\n",
        "    cv2.imwrite(path, crop)\n",
        "    return path\n",
        "\n",
        "\n",
        "def insert_db(cursor, frame_id, track_id, vlabel, vx1, vy1, vx2, vy2,\n",
        "              x1, y1, x2, y2, plate_text, ocr_confidence):\n",
        "    \"\"\"Insert detection into SQLite DB.\"\"\"\n",
        "    cursor.execute(\n",
        "        \"INSERT INTO plates (plate_text, ocr_confidence, frame_id, vehicle_id, vehicle_type, vehicle_bbox, plate_bbox) VALUES (?, ?, ?, ?, ?, ?, ?)\",\n",
        "        (plate_text, ocr_confidence, frame_id, track_id, vlabel,\n",
        "         f\"{vx1},{vy1},{vx2},{vy2}\", f\"{x1},{y1},{x2},{y2}\")\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Detection helpers\n",
        "# ---------------------------\n",
        "def detect_vehicles(frame, vehicle_model, tracker, conf=0.25):\n",
        "    results = vehicle_model(frame, imgsz=640, conf=conf)[0]\n",
        "    detections, vehicle_data = [], []\n",
        "    for box in results.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        vlabel = vehicle_model.names[cls_id]\n",
        "        if vlabel in [\"car\", \"bus\", \"motorcycle\", \"truck\"]:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            score = float(box.conf[0])\n",
        "            detections.append([x1, y1, x2, y2, score])\n",
        "            vehicle_data.append((x1, y1, x2, y2, vlabel))\n",
        "    tracked_objects = tracker.update(np.array(detections) if len(detections) > 0 else np.empty((0, 5)))\n",
        "    return tracked_objects, vehicle_data\n",
        "\n",
        "\n",
        "def detect_plates(frame, plate_model, conf=0.25):\n",
        "    results = plate_model(frame, imgsz=1280, conf=conf)[0]\n",
        "    return [tuple(map(int, box.xyxy[0])) for box in results.boxes]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Main ANPR pipeline\n",
        "# ---------------------------\n",
        "def run_npr(video_path, output_dir, conf=0.25):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # --- Setup DB ---\n",
        "    db_path = os.path.join(output_dir, \"plates_final.db\")\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    c = conn.cursor()\n",
        "    c.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS plates\n",
        "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "     plate_text TEXT,\n",
        "     ocr_confidence REAL,\n",
        "     timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "     frame_id INTEGER,\n",
        "     vehicle_id INTEGER,\n",
        "     vehicle_type TEXT,\n",
        "     vehicle_bbox TEXT,\n",
        "     plate_bbox TEXT)\n",
        "    ''')\n",
        "    conn.commit()\n",
        "\n",
        "    # --- Load models ---\n",
        "    vehicle_model = YOLO(\"yolov8s.pt\")   # vehicles\n",
        "    plate_model   = YOLO(\"/content/best.pt\")  # license plates\n",
        "\n",
        "    # --- Video setup ---\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
        "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    print(f\"Video resolution: {width}x{height}, FPS={fps}\")\n",
        "\n",
        "    out_path = os.path.join(output_dir, \"annotated_video_final.mp4\")\n",
        "    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
        "\n",
        "    tracker = Sort(max_age=5, min_hits=3, iou_threshold=0.1)\n",
        "    frame_count, db_inserts = 0, 0\n",
        "    ocr_confidences = []\n",
        "\n",
        "    # --- Processing loop ---\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_count += 1\n",
        "\n",
        "        tracked_objects, vehicle_data = detect_vehicles(frame, vehicle_model, tracker, conf=conf)\n",
        "        plate_boxes = detect_plates(frame, plate_model, conf=conf)\n",
        "        print(f\"[Frame {frame_count}] Vehicles={len(vehicle_data)}, Plates={len(plate_boxes)}\")\n",
        "\n",
        "        for (x1, y1, x2, y2) in plate_boxes:\n",
        "            # Match plate with vehicles\n",
        "            matched_vehicle, best_iou, matched_track_id, matched_vlabel = None, 0, -1, \"UNKNOWN\"\n",
        "            for (vx1, vy1, vx2, vy2, vlabel) in vehicle_data:\n",
        "                for (tx1, ty1, tx2, ty2, track_id) in tracked_objects:\n",
        "                    iou = compute_iou([x1,y1,x2,y2], [tx1,ty1,tx2,ty2])\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        matched_vehicle = (vx1, vy1, vx2, vy2)\n",
        "                        matched_track_id = int(track_id)\n",
        "                        matched_vlabel = vlabel\n",
        "\n",
        "            # OCR\n",
        "            plate_crop = frame[y1:y2, x1:x2]\n",
        "            save_crop(plate_crop, frame_count, output_dir)\n",
        "            preprocessed = preprocess_plate(plate_crop)\n",
        "            plate_text, ocr_conf = read_plate_text(preprocessed)\n",
        "            ocr_confidences.append(ocr_conf)\n",
        "\n",
        "            # Save if valid\n",
        "            if plate_text != \"UNKNOWN\" and ocr_conf > 0.3:\n",
        "                vx1, vy1, vx2, vy2 = matched_vehicle if matched_vehicle else (-1, -1, -1, -1)\n",
        "                insert_db(c, frame_count, matched_track_id, matched_vlabel,\n",
        "                          vx1, vy1, vx2, vy2, x1, y1, x2, y2,\n",
        "                          plate_text, ocr_conf)\n",
        "                conn.commit()\n",
        "                db_inserts += 1\n",
        "\n",
        "            # Draw\n",
        "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "            cv2.putText(frame, f\"{plate_text} ({ocr_conf:.2f})\", (x1, y1-5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "            if matched_vehicle:\n",
        "                vx1, vy1, vx2, vy2 = matched_vehicle\n",
        "                cv2.rectangle(frame, (vx1,vy1), (vx2,vy2), (255,0,0), 2)\n",
        "                cv2.putText(frame, f\"{matched_vlabel} ID {matched_track_id}\", (vx1, vy1-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)\n",
        "\n",
        "        if frame_count % 30 == 0:\n",
        "            cv2_imshow(frame)\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    conn.close()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Confidence stats\n",
        "    if ocr_confidences:\n",
        "        print(f\"OCR confidence: min={min(ocr_confidences):.2f}, max={max(ocr_confidences):.2f}, avg={np.mean(ocr_confidences):.2f}\")\n",
        "\n",
        "    print(f\"✅ Video saved: {out_path}\")\n",
        "    print(f\"✅ Database saved: {db_path} with {db_inserts} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zfhnUwvAqJHA"
      },
      "outputs": [],
      "source": [
        "# Video path and Outeput_dir\n",
        "video_path=\"/content/drive/MyDrive/YOLO_project/Traffic_Control_CCTV.mp4\"\n",
        "output_dir=\"/content/drive/MyDrive/YOLO_project/output\"\n",
        "run_npr(video_path,output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5FauFv3S0gM"
      },
      "source": [
        "## Utiltity Function For Database Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT4KLhf3ZsEU"
      },
      "outputs": [],
      "source": [
        "def read_plates_db(db_path):\n",
        "    \"\"\"\n",
        "    Read and summarize plates.db into a nice Pandas DataFrame.\n",
        "\n",
        "\n",
        "    Args:\n",
        "        db_path (str): Path to plates.db\n",
        "    Returns:\n",
        "        DataFrame with plate summary\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    query = \"\"\"\n",
        "        SELECT plate_text,\n",
        "               vehicle_id,\n",
        "               vehicle_type,\n",
        "               MIN(frame_id) AS first_seen,\n",
        "               MAX(frame_id) AS last_seen,\n",
        "               COUNT(*) AS times_seen,\n",
        "               *\n",
        "        FROM plates\n",
        "        GROUP BY plate_text, vehicle_id, vehicle_type\n",
        "        ORDER BY first_seen;\n",
        "    \"\"\"\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# Removing Unnecessary Rows\n",
        "def summarize_and_save(raw_db_path, summary_db_path, conf_thresh=0.8):\n",
        "    \"\"\"\n",
        "    Summarize raw ANPR results into a clean database.\n",
        "\n",
        "    Steps:\n",
        "    1. Load all rows from `plates` table in raw_db_path.\n",
        "    2. Filter invalid rows:\n",
        "       - vehicle_id != -1\n",
        "       - plate_text != 'UNKNOWN'\n",
        "       - ocr_confidence >= conf_thresh\n",
        "    3. Keep ALL rows with ocr_confidence == 1.0.\n",
        "    4. For each vehicle_id with lower confidence, keep only the highest one.\n",
        "    5. Drop duplicate plate_text (keep best confidence per plate_text).\n",
        "    6. Save the summary to a new SQLite DB under `plates_summary`.\n",
        "    \"\"\"\n",
        "    # Load raw detections\n",
        "    conn = sqlite3.connect(raw_db_path)\n",
        "    try:\n",
        "        df = pd.read_sql_query(\"SELECT * FROM plates\", conn)\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"⚠️ No rows found in raw database.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Clean rows\n",
        "    df_clean = df[(df[\"vehicle_id\"] != -1) &\n",
        "                  (df[\"plate_text\"] != \"UNKNOWN\") &\n",
        "                  (df[\"ocr_confidence\"] >= conf_thresh)]\n",
        "\n",
        "    if df_clean.empty:\n",
        "        print(\"⚠️ No valid rows after filtering.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Split: perfect vs imperfect\n",
        "    perfect = df_clean[df_clean[\"ocr_confidence\"] == 1.0]\n",
        "    imperfect = df_clean[df_clean[\"ocr_confidence\"] < 1.0]\n",
        "\n",
        "    # Pick best per vehicle_id only from imperfect\n",
        "    imperfect_best = imperfect.loc[imperfect.groupby(\"vehicle_id\")[\"ocr_confidence\"].idxmax()]\n",
        "\n",
        "    # Combine both sets\n",
        "    summary = pd.concat([perfect, imperfect_best], ignore_index=True)\n",
        "\n",
        "    # Drop duplicates by plate_text (keep highest confidence)\n",
        "    summary = summary.sort_values(\"ocr_confidence\", ascending=False)\n",
        "    summary = summary.drop_duplicates(subset=[\"plate_text\"], keep=\"first\")\n",
        "\n",
        "    # Save summary DB\n",
        "    conn_sum = sqlite3.connect(summary_db_path)\n",
        "    try:\n",
        "        summary.to_sql(\"plates_summary\", conn_sum, if_exists=\"replace\", index=False)\n",
        "    finally:\n",
        "        conn_sum.close()\n",
        "\n",
        "    print(f\"✅ Summary saved: {summary_db_path} with {len(summary)} unique plates\")\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNxLsDPppmai"
      },
      "outputs": [],
      "source": [
        "raw_db_path = \"/content/drive/MyDrive/YOLO_project/output/plates4.db\"\n",
        "   # --- Create summary ---\n",
        "summary_db_path = os.path.join(output_dir, \"plates_summary_uk.db\")\n",
        "summarize_and_save(raw_db_path, summary_db_path)\n",
        "df = read_plates_db(raw_db_path)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TwlD_98ppja"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATueacFfV9M1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
